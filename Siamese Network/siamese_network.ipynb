{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t37o4I-3obHH"
   },
   "source": [
    "## Importing libraries, initialising global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imageio in /scratch/users/asafa22/.conda/envs/tf/lib/python3.9/site-packages (2.24.0)\n",
      "Requirement already satisfied: pillow>=8.3.2 in /scratch/users/asafa22/.conda/envs/tf/lib/python3.9/site-packages (from imageio) (9.4.0)\n",
      "Requirement already satisfied: numpy in /scratch/users/asafa22/.conda/envs/tf/lib/python3.9/site-packages (from imageio) (1.24.1)\n",
      "Requirement already satisfied: pandas in /scratch/users/asafa22/.conda/envs/tf/lib/python3.9/site-packages (1.5.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /scratch/users/asafa22/.conda/envs/tf/lib/python3.9/site-packages (from pandas) (2022.7.1)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /scratch/users/asafa22/.conda/envs/tf/lib/python3.9/site-packages (from pandas) (1.24.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /scratch/users/asafa22/.conda/envs/tf/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /scratch/users/asafa22/.conda/envs/tf/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement glob (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for glob\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install imageio\n",
    "!pip install pandas\n",
    "!pip install glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "_cell_guid": "b9556bde-e5b6-4643-9afe-82298daf444e",
    "_uuid": "4df1608c-a2a9-48f9-8812-af1b5cdf1b16",
    "executionInfo": {
     "elapsed": 2656,
     "status": "ok",
     "timestamp": 1673868375616,
     "user": {
      "displayName": "Abdulfattah Safa",
      "userId": "07397629325699666682"
     },
     "user_tz": -180
    },
    "id": "7CNvDBi7obHL"
   },
   "outputs": [],
   "source": [
    "import imageio\n",
    "import os\n",
    "import pandas as pd\n",
    "from statistics import median\n",
    "from random import randint\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.layers.core import Flatten, Dropout\n",
    "from keras.layers import Input, Dense, Lambda, Layer\n",
    "from keras import backend as K\n",
    "from keras import applications\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.applications.resnet import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.applications.resnet import ResNet152\n",
    "\n",
    "num_samples = 29000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30296,
     "status": "ok",
     "timestamp": 1673868405908,
     "user": {
      "displayName": "Abdulfattah Safa",
      "userId": "07397629325699666682"
     },
     "user_tz": -180
    },
    "id": "ScOHayjAqhU0",
    "outputId": "a9c207ed-33f3-4c83-c117-2ff5a471da7e"
   },
   "outputs": [],
   "source": [
    "use_colab=False\n",
    "wikiHow=True\n",
    "\n",
    "# Path to folder containing images\n",
    "if use_colab:\n",
    "  from google.colab import drive\n",
    "  \n",
    "  drive.mount('/content/drive')\n",
    "  dataset_directory = '/content/drive/MyDrive/Colab/datasets/wikihow'\n",
    "  workspace = '/content/drive/MyDrive/Colab/wikihow/Siamese'\n",
    "else:\n",
    "  dataset_directory = '/kuacc/users/asafa22/google-drive/wikihow'\n",
    "  workspace = '/kuacc/users/asafa22/workspace/wikihow/Siamese'\n",
    "  #workspace = \"./\"\n",
    "\n",
    "if wikiHow:\n",
    "    text_image_mapping_file_path = os.path.join(workspace, 'articles.csv')\n",
    "else:\n",
    "    text_image_mapping_file_path = os.path.join(dataset_directory, 'keys.csv')\n",
    "\n",
    "word_vector_file_path = os.path.join(workspace, \"word2vec_gensim.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xPpnmyfIobHO"
   },
   "source": [
    "## Generator function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1673868405909,
     "user": {
      "displayName": "Abdulfattah Safa",
      "userId": "07397629325699666682"
     },
     "user_tz": -180
    },
    "id": "T37PuCDJobHQ"
   },
   "outputs": [],
   "source": [
    "\n",
    "# data generator for neural network\n",
    "# forms correct and incorrect pairings of images with text descriptions and labels them as correct (1) or incorrect (0)\n",
    "\n",
    "def generator(batch_size, df):\n",
    "    \n",
    "    batch_img = np.zeros((batch_size, 224, 224, 3))\n",
    "    batch_txt = np.zeros((batch_size, 512))\n",
    "    batch_labels = np.zeros((batch_size,1))\n",
    "    \n",
    "    video_ids = df['image']\n",
    "    video_txt = df['txt_enc']\n",
    "    \n",
    "    length = len(df) -1\n",
    "    \n",
    "    while True:\n",
    "        for i in range(batch_size//2):\n",
    "            \n",
    "            i = i*2\n",
    "            \n",
    "            #correct\n",
    "            sample = randint(0,length)\n",
    "            file = video_ids.iloc[sample]\n",
    "            \n",
    "            correct_txt = video_txt.iloc[sample]\n",
    "            \n",
    "            im = load_img(file, target_size=(224, 224))\n",
    "            im = img_to_array(im)\n",
    "            im = np.expand_dims(im, axis=0)\n",
    "            im = preprocess_input(im)\n",
    "            \n",
    "            batch_img[i-2] = im\n",
    "            batch_txt[i-2] = correct_txt\n",
    "            batch_labels[i-2] = 1\n",
    "                       \n",
    "            #incorrect \n",
    "            file = video_ids.iloc[randint(0,length)]\n",
    "                       \n",
    "            im = load_img(file, target_size=(224, 224))\n",
    "            im = img_to_array(im)\n",
    "            im = np.expand_dims(im, axis=0)\n",
    "            im = preprocess_input(im)\n",
    "\n",
    "            batch_img[i-1] = im\n",
    "            batch_txt[i-1] = correct_txt\n",
    "            batch_labels[i-1] = 0\n",
    "                        \n",
    "        yield [batch_txt, batch_img], batch_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Jd2CQ73obHS"
   },
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1673868405909,
     "user": {
      "displayName": "Abdulfattah Safa",
      "userId": "07397629325699666682"
     },
     "user_tz": -180
    },
    "id": "Ye8dgWGgobHT"
   },
   "outputs": [],
   "source": [
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    return K.sqrt(K.maximum(K.sum(K.square(x - y), axis=1, keepdims=True), K.epsilon()))\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    margin = 1\n",
    "    return K.mean(y_true * K.square(y_pred) + (1 - y_true) * K.square(K.maximum(margin - y_pred, 0)))\n",
    "\n",
    "def create_img_encoder(input_dim, resnet):\n",
    "    x = Sequential()\n",
    "    x.add(resnet)\n",
    "    x.add(Dense(500, activation=\"relu\"))\n",
    "    x.add(Dropout(0.5))\n",
    "    x.add(Dense(512, activation=\"relu\"))\n",
    "    return x\n",
    "\n",
    "def create_txt_encoder(input_dim):\n",
    "    x = Sequential()\n",
    "    x.add(Dense(500, input_shape = (512,), activation=\"relu\"))\n",
    "    x.add(Dropout(0.5))\n",
    "    x.add(Dense(512, activation=\"relu\"))\n",
    "    return x\n",
    "\n",
    "def compute_accuracy(predictions, labels):\n",
    "    return labels[predictions.ravel() < 0.5].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3T5g0oNbobHV"
   },
   "source": [
    "## Initialise ResNet152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7943,
     "status": "ok",
     "timestamp": 1673868413849,
     "user": {
      "displayName": "Abdulfattah Safa",
      "userId": "07397629325699666682"
     },
     "user_tz": -180
    },
    "id": "-77a0Xr8obHV",
    "outputId": "e164607f-59d4-4b3d-dc6a-f7acaa5f44f5"
   },
   "outputs": [],
   "source": [
    "#resnet = ResNet152(include_top=True, weights='imagenet')\n",
    "resnet = ResNet152(include_top=True, weights=None)\n",
    "\n",
    "for layer in resnet.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "luQkh4-XobHX"
   },
   "source": [
    "## Creating model and loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2787,
     "status": "ok",
     "timestamp": 1673868416612,
     "user": {
      "displayName": "Abdulfattah Safa",
      "userId": "07397629325699666682"
     },
     "user_tz": -180
    },
    "id": "x92fCwLmobHX",
    "outputId": "91924b00-10a2-4018-fa68-d633582d15e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_14 (InputLayer)          [(None, 512)]        0           []                               \n",
      "                                                                                                  \n",
      " input_15 (InputLayer)          [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " sequential_8 (Sequential)      (None, 512)          513012      ['input_14[0][0]']               \n",
      "                                                                                                  \n",
      " sequential_9 (Sequential)      (None, 512)          61176956    ['input_15[0][0]']               \n",
      "                                                                                                  \n",
      " lambda_4 (Lambda)              (None, 1)            0           ['sequential_8[0][0]',           \n",
      "                                                                  'sequential_9[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 61,689,968\n",
      "Trainable params: 1,270,024\n",
      "Non-trainable params: 60,419,944\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kuacc/users/asafa22/.conda/envs/tf/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "input_txt = Input(shape=(512,))\n",
    "input_img = Input(shape=(224, 224, 3))\n",
    "\n",
    "txt_enc = create_txt_encoder(input_txt)\n",
    "img_enc = create_img_encoder(input_img, resnet)\n",
    "\n",
    "encoded_txt = txt_enc(input_txt)\n",
    "encoded_img = img_enc(input_img)\n",
    "\n",
    "distance = Lambda(euclidean_distance, output_shape=eucl_dist_output_shape)([encoded_txt, encoded_img])\n",
    "\n",
    "model = Model([input_txt, input_img], distance)\n",
    "\n",
    "adam = Adam(lr=0.00001)\n",
    "model.compile(loss=contrastive_loss, optimizer=adam)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "executionInfo": {
     "elapsed": 1634,
     "status": "ok",
     "timestamp": 1673868418237,
     "user": {
      "displayName": "Abdulfattah Safa",
      "userId": "07397629325699666682"
     },
     "user_tz": -180
    },
    "id": "e2mh48irobHY"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "if wikiHow:\n",
    "    dataset = pd.read_csv(text_image_mapping_file_path, header=0)\n",
    "    image_pah = dataset['image']\n",
    "else:\n",
    "    # The CSV generated by the word2vec(gensim) model\n",
    "    #img_paths = [DATASET_PATH + str(i) + '.jpg' for i in range(12305)]\n",
    "    df = pd.read_csv(text_image_mapping_file_path)\n",
    "    img_paths = df.iloc[:, 1]\n",
    "    dataset = pd.DataFrame()\n",
    "    dataset['image'] = pd.Series(img_paths)\n",
    "\n",
    "\n",
    "# append dataset directory to image paths #\n",
    "dataset['image'] = dataset_directory +\"/\"+dataset['image'].astype(str)\n",
    "# append word vector data to dataset #\n",
    "data = pd.read_csv(word_vector_file_path, header=None)\n",
    "data = list(np.array(data))\n",
    "dataset['txt_enc'] = pd.Series(data)\n",
    "\n",
    "# shuffle the dataset\n",
    "dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
    "# split data into train, validation and test #\n",
    "df_test = dataset[num_samples:]\n",
    "dataset = dataset[:num_samples]\n",
    "\n",
    "df_train = dataset[:int(num_samples*0.8)]\n",
    "df_val = dataset[int(num_samples*0.8):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aES0ha1fobHa"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 416
    },
    "executionInfo": {
     "elapsed": 868306,
     "status": "error",
     "timestamp": 1673869286539,
     "user": {
      "displayName": "Abdulfattah Safa",
      "userId": "07397629325699666682"
     },
     "user_tz": -180
    },
    "id": "mrlWYM3aobHb",
    "outputId": "c579f016-f0a7-45e5-a746-e44fe7ee6d0f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87641/2745313800.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(generator(30, df_train), steps_per_epoch= int(int(num_samples*0.8)/30), validation_data= generator(30, df_val), validation_steps=int(int(num_samples*0.2)/30), epochs=num_of_epochs, verbose=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/55\n",
      " 23/773 [..............................] - ETA: 3:00 - loss: 16.9520"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-24 22:19:21.381783: W tensorflow/core/framework/op_kernel.cc:1818] UNKNOWN: FileNotFoundError: [Errno 2] No such file or directory: '/kuacc/users/asafa22/google-drive/wikihow/nan'\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/kuacc/users/asafa22/.conda/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/kuacc/users/asafa22/.conda/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/kuacc/users/asafa22/.conda/envs/tf/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1039, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "\n",
      "  File \"/kuacc/users/asafa22/.conda/envs/tf/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 901, in wrapped_generator\n",
      "    for data in generator_fn():\n",
      "\n",
      "  File \"/tmp/ipykernel_87641/4150225356.py\", line 26, in generator\n",
      "    im = load_img(file, target_size=(224, 224))\n",
      "\n",
      "  File \"/kuacc/users/asafa22/.conda/envs/tf/lib/python3.9/site-packages/keras/utils/image_utils.py\", line 422, in load_img\n",
      "    with open(path, \"rb\") as f:\n",
      "\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/kuacc/users/asafa22/google-drive/wikihow/nan'\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Graph execution error:\n\n2 root error(s) found.\n  (0) UNKNOWN:  FileNotFoundError: [Errno 2] No such file or directory: '/kuacc/users/asafa22/google-drive/wikihow/nan'\nTraceback (most recent call last):\n\n  File \"/kuacc/users/asafa22/.conda/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"/kuacc/users/asafa22/.conda/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/kuacc/users/asafa22/.conda/envs/tf/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1039, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/kuacc/users/asafa22/.conda/envs/tf/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 901, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/tmp/ipykernel_87641/4150225356.py\", line 26, in generator\n    im = load_img(file, target_size=(224, 224))\n\n  File \"/kuacc/users/asafa22/.conda/envs/tf/lib/python3.9/site-packages/keras/utils/image_utils.py\", line 422, in load_img\n    with open(path, \"rb\") as f:\n\nFileNotFoundError: [Errno 2] No such file or directory: '/kuacc/users/asafa22/google-drive/wikihow/nan'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n  (1) CANCELLED:  Function was cancelled before it was started\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_141970]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m num_of_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m55\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m0.8\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_of_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m weights_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(workspace,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweights.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39msave_weights(weights_file)\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.9/site-packages/keras/engine/training.py:2604\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2592\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[1;32m   2593\u001b[0m \n\u001b[1;32m   2594\u001b[0m \u001b[38;5;124;03mDEPRECATED:\u001b[39;00m\n\u001b[1;32m   2595\u001b[0m \u001b[38;5;124;03m  `Model.fit` now supports generators, so there is no longer any need to\u001b[39;00m\n\u001b[1;32m   2596\u001b[0m \u001b[38;5;124;03m  use this endpoint.\u001b[39;00m\n\u001b[1;32m   2597\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2598\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   2599\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Model.fit_generator` is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2600\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in a future version. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2601\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2602\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m   2603\u001b[0m )\n\u001b[0;32m-> 2604\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2605\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2606\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2607\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2608\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2609\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2610\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2611\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2612\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2613\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2615\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2616\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2617\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2618\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2619\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mUnknownError\u001b[0m: Graph execution error:\n\n2 root error(s) found.\n  (0) UNKNOWN:  FileNotFoundError: [Errno 2] No such file or directory: '/kuacc/users/asafa22/google-drive/wikihow/nan'\nTraceback (most recent call last):\n\n  File \"/kuacc/users/asafa22/.conda/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"/kuacc/users/asafa22/.conda/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/kuacc/users/asafa22/.conda/envs/tf/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1039, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/kuacc/users/asafa22/.conda/envs/tf/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 901, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/tmp/ipykernel_87641/4150225356.py\", line 26, in generator\n    im = load_img(file, target_size=(224, 224))\n\n  File \"/kuacc/users/asafa22/.conda/envs/tf/lib/python3.9/site-packages/keras/utils/image_utils.py\", line 422, in load_img\n    with open(path, \"rb\") as f:\n\nFileNotFoundError: [Errno 2] No such file or directory: '/kuacc/users/asafa22/google-drive/wikihow/nan'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n  (1) CANCELLED:  Function was cancelled before it was started\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_141970]"
     ]
    }
   ],
   "source": [
    "num_of_epochs = 55\n",
    "model.fit_generator(generator(30, df_train), steps_per_epoch= int(int(num_samples*0.8)/30), validation_data= generator(30, df_val), validation_steps=int(int(num_samples*0.2)/30), epochs=num_of_epochs, verbose=1)\n",
    "weights_file = os.path.join(workspace,'weights.h5')\n",
    "model.save_weights(weights_file)\n",
    "model.save('model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n6aJV10WobHb"
   },
   "source": [
    "## Load saved weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "aborted",
     "timestamp": 1673869286540,
     "user": {
      "displayName": "Abdulfattah Safa",
      "userId": "07397629325699666682"
     },
     "user_tz": -180
    },
    "id": "wgSxvtsrobHb"
   },
   "outputs": [],
   "source": [
    "# Load from where you stored the weights\n",
    "model.load_weights(weights_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2SLZVox5obHd"
   },
   "source": [
    "## Decide size of test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "aborted",
     "timestamp": 1673869286848,
     "user": {
      "displayName": "Abdulfattah Safa",
      "userId": "07397629325699666682"
     },
     "user_tz": -180
    },
    "id": "mZgSAMXxobHd"
   },
   "outputs": [],
   "source": [
    "subset_size = 200\n",
    "subset = df_test.iloc[:subset_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IQnoQLbZobHd"
   },
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "aborted",
     "timestamp": 1673869286849,
     "user": {
      "displayName": "Abdulfattah Safa",
      "userId": "07397629325699666682"
     },
     "user_tz": -180
    },
    "id": "4J7OWSyGobHd"
   },
   "outputs": [],
   "source": [
    "# metrics - img -> text\n",
    "\n",
    "mr = []\n",
    "top_1_count = 0\n",
    "top_5_count = 0\n",
    "top_10_count = 0\n",
    "\n",
    "for i in range(subset_size):\n",
    "    file = subset['image'].iloc[i]\n",
    "    im = load_img(file, target_size=(224, 224))\n",
    "    im = img_to_array(im)\n",
    "    im = np.expand_dims(im, axis=0)\n",
    "    im = preprocess_input(im)\n",
    "    \n",
    "    image_array = np.zeros((subset_size, 224, 224, 3))\n",
    "    for k in range(subset_size):\n",
    "        image_array[k] = im\n",
    "        \n",
    "    txt_array = np.zeros((subset_size, 512))\n",
    "    for j in range(subset_size):\n",
    "        txt = subset['txt_enc'].iloc[j]\n",
    "        txt_array[j] = txt\n",
    "    \n",
    "    predictions = [pred[0] for pred in model.predict([txt_array, image_array])]\n",
    "    pred_i = predictions[i]\n",
    "    predictions.sort()\n",
    "    rank = predictions.index(pred_i)\n",
    "    if rank < 10:\n",
    "        top_10_count += 1\n",
    "    if rank < 5:\n",
    "        top_5_count += 1\n",
    "    if rank < 1:\n",
    "        top_1_count += 1\n",
    "    mr.append(rank+1)     \n",
    "\n",
    "print('Median Rank(img->txt):', median(mr)*100/subset_size, '%')\n",
    "print('R@1(img->txt):', top_1_count*100/subset_size, '%')\n",
    "print('R@5(img->txt):', top_5_count*100/subset_size, '%')\n",
    "print('R@10(img->txt):', top_10_count*100/subset_size, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "aborted",
     "timestamp": 1673869286849,
     "user": {
      "displayName": "Abdulfattah Safa",
      "userId": "07397629325699666682"
     },
     "user_tz": -180
    },
    "id": "a7YkBwZoobHd"
   },
   "outputs": [],
   "source": [
    "# metrics - txt -> img\n",
    "\n",
    "mr = []\n",
    "top_1_count = 0\n",
    "top_5_count = 0\n",
    "top_10_count = 0\n",
    "\n",
    "for i in range(subset_size):\n",
    "    txt = subset['txt_enc'].iloc[i] \n",
    "    txt_array = np.zeros((subset_size, 512))\n",
    "    for k in range(subset_size):\n",
    "        txt_array[k] = txt\n",
    "        \n",
    "        \n",
    "    image_array = np.zeros((subset_size, 224, 224, 3))\n",
    "    for j in range(subset_size):\n",
    "        file = subset['image'].iloc[j]\n",
    "        im = load_img(file, target_size=(224, 224))\n",
    "        im = img_to_array(im)\n",
    "        im = np.expand_dims(im, axis=0)\n",
    "        im = preprocess_input(im)\n",
    "        image_array[k] = im\n",
    "    \n",
    "    predictions = [pred[0] for pred in model.predict([txt_array, image_array])]\n",
    "    pred_i = predictions[i]\n",
    "    predictions.sort()\n",
    "    rank = predictions.index(pred_i)\n",
    "    if rank < 10:\n",
    "        top_10_count += 1\n",
    "    if rank < 5:\n",
    "        top_5_count += 1\n",
    "    if rank < 1:\n",
    "        top_1_count += 1\n",
    "    mr.append(rank+1)     \n",
    "\n",
    "print('Median Rank(txt->img):', median(mr)*100/subset_size, '%')\n",
    "print('R@1(txt->img):', top_1_count*100/subset_size, '%')\n",
    "print('R@5(txt->img):', top_5_count*100/subset_size, '%')\n",
    "print('R@10(txt->img):', top_10_count*100/subset_size, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z8LTe6sGobHf"
   },
   "source": [
    "## Download Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "aborted",
     "timestamp": 1673869286849,
     "user": {
      "displayName": "Abdulfattah Safa",
      "userId": "07397629325699666682"
     },
     "user_tz": -180
    },
    "id": "osTWoctwobHf"
   },
   "outputs": [],
   "source": [
    "# download weights\n",
    "\n",
    "from IPython.display import FileLink\n",
    "\n",
    "FileLink(weights_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XObkIosAobHf"
   },
   "source": [
    "## Try predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1673869286850,
     "user": {
      "displayName": "Abdulfattah Safa",
      "userId": "07397629325699666682"
     },
     "user_tz": -180
    },
    "id": "s7pceQ4dobHg"
   },
   "outputs": [],
   "source": [
    "# trying out predict\n",
    "\n",
    "text = np.zeros((2, 512))\n",
    "image = np.zeros((2, 224, 224, 3))\n",
    "\n",
    "file = dataset['image'].iloc[21]     \n",
    "correct_txt = dataset['txt_enc'].iloc[21]\n",
    "\n",
    "im = load_img(file, target_size=(224, 224))\n",
    "im = img_to_array(im)\n",
    "im = np.expand_dims(im, axis=0)\n",
    "im = preprocess_input(im)\n",
    "\n",
    "image[0] = im\n",
    "\n",
    "text[0] = correct_txt\n",
    "\n",
    "file = dataset['image'].iloc[21]     \n",
    "correct_txt = dataset['txt_enc'].iloc[90]\n",
    "\n",
    "im = load_img(file, target_size=(224, 224))\n",
    "im = img_to_array(im)\n",
    "im = np.expand_dims(im, axis=0)\n",
    "im = preprocess_input(im)\n",
    "\n",
    "image[1] = im\n",
    "\n",
    "text[1] = correct_txt\n",
    "\n",
    "model.predict([text, image])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
